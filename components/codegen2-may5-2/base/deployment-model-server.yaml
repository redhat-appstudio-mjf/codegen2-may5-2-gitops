apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: codegen2-may5-2-model-server
    app.kubernetes.io/managed-by: kustomize
    app.kubernetes.io/name: codegen2-may5-2-model-server
    app.kubernetes.io/part-of: codegen2-may5-2
  name: codegen2-may5-2-model-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: codegen2-may5-2-model-server
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: codegen2-may5-2-model-server
    spec:
      containers:
        - image: quay.io/redhat-ai-dev/vllm-openai-ubi9:v0.8.4
          args: ["--model", "mistralai/Mistral-7B-Instruct-v0.2", "--port", "8001", "--download-dir", "/models-cache", "--max-model-len", "4096"]
          resources:
            limits:
              nvidia.com/gpu: '1'
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: models-cache
              mountPath: /models-cache
          name: app-model-service
          ports:
            - containerPort: 8001
          securityContext:
            runAsNonRoot: true
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: "2Gi"
        - name: models-cache
          persistentVolumeClaim:
            claimName: codegen2-may5-2
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
